{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hano\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\hano\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hano\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hano\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hano\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hano\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Hano\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reduce from functools, numpy and pandas\n",
    "from functools import reduce\n",
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location = '../data/58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13637"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prophet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'EBook', 'of', 'The', 'Prophet,', 'by', 'Kahlil', 'Gibran\\n\\nThis', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and\\nmost', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions\\nwhatsoever.', '', 'You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms\\nof', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at\\nwww.gutenberg.org.', '', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States,', \"you'll\\nhave\", 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using\\nthis', 'ebook.\\n\\n\\n\\nTitle:', 'The', 'Prophet\\n\\nAuthor:', 'Kahlil', 'Gibran\\n\\nRelease', 'Date:', 'January', '1,', '2019', '[EBook', '#58585]\\nLast', 'Updated:', 'January', '3,', '2018\\n\\n\\nLanguage:', 'English\\n\\nCharacter', 'set', 'encoding:', 'UTF-8\\n\\n***', 'START', 'OF', 'THIS', 'PROJECT', 'GUTENBERG', 'EBOOK', 'THE', 'PROPHET', '***\\n\\n\\n\\n\\nProduced', 'by', 'David', 'Widger', 'from', 'page', 'images', 'generously\\nprovided', 'by', 'the', 'Internet', \"Archive\\n\\n\\nTranscriber's\", 'Note:', 'Page', 'numbers,', 'ie:', '{20},', 'are', 'included', 'in', 'this\\nutf-8', 'text', 'file.', 'For', 'those', 'wishing', 'to', 'use', 'a', 'text', 'file', 'unencumbered\\nwith', 'page', 'numbers', 'open', 'or', 'download', 'the', 'Latin-1', 'file', '58585-8.txt.\\n\\n\\n\\n\\n\\n\\n\\nTHE', 'PROPHET\\n\\nBy', 'Kahlil', 'Gibran\\n\\nNew', 'York:', 'Alfred', 'A.', 'Knopf\\n\\n1923\\n\\n_The', 'Twelve', 'Illustrations', 'In', 'This', 'Volume\\nAre', 'Reproduced', 'From', 'Original', 'Drawings', 'By\\nThe', 'Author_\\n\\n\\n“His', 'power', 'came', 'from', 'some', 'great', 'reservoir\\nof', 'spiritual', 'life', 'else', 'it', 'could', 'not', 'have\\nbeen', 'so', 'universal', 'and', 'so', 'potent,', 'but', 'the\\nmajesty', 'and', 'beauty', 'of', 'the', 'language', 'with\\nwhich', 'he', 'clothed', 'it', 'were', 'all', 'his', 'own?”\\n\\n--Claude', 'Bragdon\\n\\n\\nTHE', 'BOOKS', 'OF', 'KAHLIL', 'GIBRAN\\n\\nThe', 'Madman.', '1918', 'Twenty', 'Drawings.', '1919\\nThe', 'Forerunner.', '1920', 'The', 'Prophet.', '1923\\nSand', 'and', 'Foam.', '1926', 'Jesus', 'the', 'Son', 'of\\nMan.', '1928', 'The', 'Forth', 'Gods.', '1931', 'The\\nWanderer.', '1932', 'The', 'Garden', 'of', 'the', 'Prophet\\n1933', 'Prose', 'Poems.', '1934', 'Nymphs', 'of', 'the\\nValley.', '1948\\n\\n\\n\\n\\nCONTENTS\\n\\n', '', '', '', '', '', '', '', '', '', 'The', 'Coming', 'of', 'the', 'Ship.......7\\n', '', '', '', '', '', '', '', '', '', 'On', 'Love.....................15\\n', '', '', '', '', '', '', '', '', '', 'On', 'Marriage.................19\\n', '', '', '', '', '', '', '', '', '', 'On', 'Children.................21\\n', '', '', '', '', '', '', '', '', '', 'On', 'Giving...................23\\n', '', '', '', '', '', '', '', '', '', 'On', 'Eating', 'and', 'Drinking......27\\n', '', '', '', '', '', '', '', '', '', 'On', 'Work.....................31\\n', '', '', '', '', '', '', '', '', '', 'On', 'Joy', 'and', 'Sorrow...........33\\n', '', '', '', '', '', '', '', '', '', 'On', 'Houses...................37\\n', '', '', '', '', '', '', '', '', '', 'On', 'Clothes..................41\\n', '', '', '', '', '', '', '', '', '', 'On', 'Buying', 'and', 'Selling.......43\\n', '', '', '', '', '', '', '', '', '', 'On', 'Crime', 'and', 'Punishment.....45\\n', '', '', '', '', '', '', '', '', '', 'On', 'Laws.....................51\\n', '', '', '', '', '', '', '', '', '', 'On', 'Freedom..................55\\n', '', '', '', '', '', '', '', '', '', 'On', 'Reason', 'and', 'Passion.......57\\n', '', '', '', '', '', '', '', '', '', 'On', 'Pain.....................60\\n', '', '', '', '', '', '', '', '', '', 'On', 'Self-Knowledge...........62\\n', '', '', '', '', '', '', '', '', '', 'On', 'Teaching.................64\\n', '', '', '', '', '', '', '', '', '', 'On', 'Friendship...............66\\n', '', '', '', '', '', '', '', '', '', 'On', 'Talking..................68\\n', '', '', '', '', '', '', '', '', '', 'On', 'Time.....................70\\n', '', '', '', '', '', '', '', '', '', 'On', 'Good', 'and', 'Evil............72\\n', '', '', '', '', '', '', '', '', '', 'On', 'Prayer...................76\\n', '', '', '', '', '', '', '', '', '', 'On', 'Pleasure.................79\\n', '', '', '', '', '', '', '', '', '', 'On', 'Beauty...................83\\n', '', '', '', '', '', '', '', '', '', 'On', 'Religion.................87\\n', '', '', '', '', '', '', '', '', '', 'On', 'Death....................90\\n', '', '', '', '', '', '', '', '', '', 'The', 'Farewell................92\\n\\n\\n\\n\\nTHE']\n",
      "568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prophet_word  = prophet \n",
    "\n",
    "prophet_cut = prophet_word [:568]\n",
    "\n",
    "print(prophet_cut)\n",
    "    \n",
    "print(len(prophet_cut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project', 'Gutenberg', 'EBook', 'of', 'The', 'Prophet,', 'by', 'Kahlil', 'Gibran\\n\\nThis', 'eBook']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(prophet_word[1:11] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the door is open in \n"
     ]
    }
   ],
   "source": [
    "def reference(x):\n",
    "    cleaned_text = x.split(\"{\") [0]\n",
    "    return cleaned_text\n",
    "\n",
    "taxt =  \"the door is open in {7:00}\"\n",
    "cleaned_text = reference (taxt)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_referene (word) :\n",
    "    return ('[A-Za-z]','' , word)\n",
    "\n",
    "    prophet_reference = list(map(remove_referene, word))\n",
    "\n",
    "    print(prophet_reference [:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    return x.split(\"\\n\")\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word1', 'word2', 'word1', 'word2', 'wodrd5']\n"
     ]
    }
   ],
   "source": [
    "prophet_reference = [\"word1\\nword2\",\"word1\\nword2\" , \"wodrd5\"]\n",
    "prophet_line = [word for sublist in map(line_break , prophet_reference) for word in sublist]\n",
    "print(prophet_line[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'o', 'r', 'd', '1', 'w', 'o', 'r', 'd', '2']\n"
     ]
    }
   ],
   "source": [
    "prophet_flat = [i for sublist in prophet_line for i in sublist]\n",
    "print(prophet_flat[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(x):\n",
    "\n",
    "    word_list = {'and ' , 'the ' , 'a' , 'an'}\n",
    "\n",
    "    return x.lower() not in word_list \n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: True if the word is not in the specified list \n",
    "    and False if the word is in the list.\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'o', 'r', 'd', '1', 'w', 'o', 'r', 'd', '2']\n"
     ]
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter , prophet_flat))\n",
    "print(prophet_filter[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "\n",
    "    return x.lower() not in word_list\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_space(a, b):\n",
    "    return a + \"\" + b\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1word2word1word2wodrd5\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "prophet_string = reduce(concat_space , prophet_filter)\n",
    "print(prophet_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
